{"cells":[{"cell_type":"code","source":["df = spark.read.table(\"Silver_SessionData\")\n","\n","from pyspark.sql.functions import to_date, hour\n","\n","df = df.withColumn(\"Date\", to_date(\"Time_stamp\"))\n","df = df.withColumn(\"Hour\", hour(\"Time_stamp\"))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"74bdeb95-e958-4303-bac4-3f48668f8250","normalized_state":"finished","queued_time":"2025-07-03T11:13:49.3305939Z","session_start_time":null,"execution_start_time":"2025-07-03T11:13:56.8520258Z","execution_finish_time":"2025-07-03T11:14:18.5000467Z","parent_msg_id":"bbdf691b-0377-4f1d-9800-451cd7f9f2d5"},"text/plain":"StatementMeta(, 74bdeb95-e958-4303-bac4-3f48668f8250, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1a4f44b9-4d98-4f03-86c7-3508436b9fb3"},{"cell_type":"code","source":["# Code generated by Data Wrangler for PySpark DataFrame\n","\n","from pyspark.sql import functions as F\n","\n","def traffic_trends(df):\n","    # Performed 1 aggregation grouped on columns: 'URI', 'Tenant'\n","    df = df.groupBy('URI', 'Tenant').agg(F.count('URI').alias('URI_count'))\n","    df = df.dropna()\n","    df = df.sort(df['URI'].asc(), df['Tenant'].asc())\n","    return df\n","\n","df_traffic_trends = traffic_trends(df)\n","df_traffic_trends.write.mode(\"overwrite\").saveAsTable(\"Gold_Traffic_trends\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":28,"statement_ids":[28],"state":"finished","livy_statement_state":"available","session_id":"3ea42fdc-8bfd-4d9c-b8da-423a5e3dc0a6","normalized_state":"finished","queued_time":"2025-07-02T10:17:09.8238788Z","session_start_time":null,"execution_start_time":"2025-07-02T10:17:09.8256439Z","execution_finish_time":"2025-07-02T10:17:18.2671801Z","parent_msg_id":"451bac80-96ce-4c56-a183-022844d00b4c"},"text/plain":"StatementMeta(, 3ea42fdc-8bfd-4d9c-b8da-423a5e3dc0a6, 28, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"28d97f3c-2402-4161-b5a2-2a4cb6e0ae09"},{"cell_type":"code","source":["# Code generated by Data Wrangler for PySpark DataFrame\n","\n","from pyspark.sql import functions as F\n","\n","def Navigation_path(df):\n","    # Remove rows where Referrer is null, empty, or NaN\n","    df = df.filter(\n","        (F.col('Referrer').isNotNull()) &\n","        (F.col('Referrer') != '') &\n","        (~F.isnan(F.col('Referrer')))\n","    )\n","\n","    # Perform aggregation\n","    df = df.groupBy('Tenant', 'URI', 'Referrer').agg(F.count('IP_Address').alias('IP_Address_count'))\n","\n","    # Sort the DataFrame\n","    df = df.sort(df['Tenant'].asc(), df['URI'].asc(), df['Referrer'].asc())\n","    \n","    return df\n","\n","df_Nav_Path = Navigation_path(df)\n","df_Nav_Path.write.mode(\"overwrite\").saveAsTable(\"Gold_Navigation_Path\")\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":30,"statement_ids":[30],"state":"finished","livy_statement_state":"available","session_id":"3ea42fdc-8bfd-4d9c-b8da-423a5e3dc0a6","normalized_state":"finished","queued_time":"2025-07-02T10:21:23.7796201Z","session_start_time":null,"execution_start_time":"2025-07-02T10:21:23.7813934Z","execution_finish_time":"2025-07-02T10:21:34.2328998Z","parent_msg_id":"6afe4678-e394-4cdd-b275-5e45868ae521"},"text/plain":"StatementMeta(, 3ea42fdc-8bfd-4d9c-b8da-423a5e3dc0a6, 30, Finished, Available, Finished)"},"metadata":{}}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fc2e834a-5c8e-43b0-9187-0942892a5662"},{"cell_type":"code","source":["import pandas as pd\n","from pyspark.sql import functions as F\n","\n","def Session_time(df):\n","    # Sort by columns: 'Tenant', 'Session_ID', 'Time_stamp'\n","    df = df.sort(df['Tenant'].asc(), df['Session_ID'].asc(), df['Time_stamp'].asc())\n","    # Group by 'Tenant' and 'Session_ID' and get first and last timestamps\n","    df = df.groupBy('Tenant', 'Session_ID').agg(\n","        F.last('Time_stamp').alias('Time_stamp_last'),\n","        F.first('Time_stamp').alias('Time_stamp_first')\n","    )\n","    df = df.dropna()\n","    pandas_df = df.toPandas()\n","    pandas_df['Time_stamp_last'] = pd.to_datetime(pandas_df['Time_stamp_last'])\n","    pandas_df['Time_stamp_first'] = pd.to_datetime(pandas_df['Time_stamp_first'])\n","    pandas_df['Session_Time'] = (pandas_df['Time_stamp_last'] - pandas_df['Time_stamp_first']).dt.total_seconds()\n","\n","    # Filter out sessions longer than 30 minutes (1800 seconds)\n","    pandas_df = pandas_df[pandas_df['Session_Time'] <= 1800]\n","    return pandas_df\n","\n","df_Session_time = Session_time(df)\n","spark_df_Session_time = spark.createDataFrame(df_Session_time)\n","\n","# Overwrite the existing table with updated schema and data\n","spark_df_Session_time.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"Gold_AvgSession_time\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"405a93c5-504e-4911-a6f1-57254e44c8a2","normalized_state":"finished","queued_time":"2025-07-03T07:30:34.0952045Z","session_start_time":null,"execution_start_time":"2025-07-03T07:30:34.0971134Z","execution_finish_time":"2025-07-03T07:30:46.6620524Z","parent_msg_id":"7f541d82-c3e0-42fd-a9fd-aba9d312fef3"},"text/plain":"StatementMeta(, 405a93c5-504e-4911-a6f1-57254e44c8a2, 9, Finished, Available, Finished)"},"metadata":{}}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9951ad65-7f02-4a00-b6a0-dca326b18e05"},{"cell_type":"code","source":["from pyspark.sql import functions as F\n","\n","def Peak_hours(df):\n","    df = df.dropna()\n","    # Convert integer hour to time string and rename column\n","    df = df.withColumn('Formatted_Hour', F.date_format(F.to_timestamp(df['Hour'].cast('string'), 'H'), 'h:mm a'))\n","    # Drop original Hour column\n","    df = df.drop('Hour')\n","    # Rename formatted column to Hour\n","    df = df.withColumnRenamed('Formatted_Hour', 'Hour')\n","    # Sort by Hour and Tenant\n","    df = df.sort(df['Hour'].asc(), df['Tenant'].asc())\n","    return df\n","\n","df_Peak_hours = Peak_hours(df)\n","df_Peak_hours.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"Gold_Peak_hours\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":29,"statement_ids":[29],"state":"finished","livy_statement_state":"available","session_id":"74bdeb95-e958-4303-bac4-3f48668f8250","normalized_state":"finished","queued_time":"2025-07-03T11:19:38.5693481Z","session_start_time":null,"execution_start_time":"2025-07-03T11:19:38.5712437Z","execution_finish_time":"2025-07-03T11:19:53.2471094Z","parent_msg_id":"04df561e-50f7-47dd-babd-a5c369ae8ecc"},"text/plain":"StatementMeta(, 74bdeb95-e958-4303-bac4-3f48668f8250, 29, Finished, Available, Finished)"},"metadata":{}}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c24df62a-89e3-42e1-a25e-e4bf407d7cfb"},{"cell_type":"markdown","source":[],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3d171396-1756-4b89-be54-c4e7d8367efd"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"b8d05a35-3e4e-474a-8d24-d30dd237ed85"}],"default_lakehouse":"b8d05a35-3e4e-474a-8d24-d30dd237ed85","default_lakehouse_name":"MyLakehouse","default_lakehouse_workspace_id":"32fd547d-9677-4d4c-8250-2d0b4a23da26"},"environment":{}}},"nbformat":4,"nbformat_minor":5}